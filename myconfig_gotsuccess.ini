[config]
# 是否使用cookie池，使用为True，反之为False，如果为True，则Cookie（下面这个参数）不被读取，在cookies.txt>中配置所有cookie
use_cookie_pool = False
# cookie 如果为不需要cookie的任务则可不填，cookie相关的具体使用规则可以查看readme中碎碎念的有关cookie
Cookie: fspop=test; cy=1503; cye=enping; _lxsdk_cuid=1861c6339dec8-09abbc9cc1216d-976273f-4b9600-1861c6339de0; _lxsdk=1861c6339dec8-09abbc9cc1216d-976273f-4b9600-1861c6339de0; _hc.v=be8f6f03-b7ef-073e-86af-5d82549a9375.1675513510; Hm_lvt_602b80cf8079ae6591966cc70a3940e7=1675513511; s_ViewType=10; Hm_lpvt_602b80cf8079ae6591966cc70a3940e7=1675977067; _lxsdk_s=1863801d0d7-a8a-48e-5f0%7C%7C15; _lx_utm=utm_source%3DBaidu%26utm_medium%3Dorganic; WEBDFPID=10u69y74w78556uy0v080075u07u10xy8136195u85197958v011w6zy-1991337093516-1675977091543OKWACUC2960edaad10e294fa6f28397fe2285902580; qruuid=833a6c35-bd06-455e-82af-58978c19b650; dplet=4e3c6518fd3eee279f13dd66c4ae2415; dper=476b11d3f5164c0af9db0a2c0d87eaf43aa9fc3cc0c82e266d4ac8053742cb26f1ecb4b4b9278c8211a14b778aa38ed0f0b7c6c91db12f0c83cd9f39b18b6098; ll=7fd06e815b796be3df069dec7836c3df; ua=mingowu; ctu=ccaf14efd3c9456cf31b6640d262457468cc6630abb364b98a178de973aacd8c
# uuid，获取方法详见文档，使用加密接口时使用
uuid : be8f6f03-b7ef-073e-86af-5d82549a9375.1675513510
# tcv，获取方法详见文档，使用加密接口时使用
tcv = ao8dsar5u0
# 默认user-agent,如果为None则为随机（仅可在不需要cookie的任务中使用,登录状态不建议随机user-agent）
user-agent = Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:109.0) Gecko/20100101 Firefox/109.0
# 保存方式  暂时支持csv和mongo
save_mode = mongo
# mongodb 链接 （mongodb://servername:port，如果本地默认端口（27017）可不填）
mongo_path = mongodb://localhost:27017
# 累计请求多少次休息多少秒，从小到大排列。例：1,2;5,10 代表每请求1次休息2秒，每5次休息10秒。
requests_times = 10,20;30,50;100,50
[detail]
# 搜索关键字
keyword = 火锅
# 位置代号，如上海为1  北京为2 广州为4，暂时不支持地名自动转换id
location_id = 8
# 频道号
channel_id = 0
# 搜索页链接，用于非'http://www.dianping.com/search/keyword/(location_id)/(channel_id)_(key_word)/p(page_nub)的情况
# 如果不填，则默认填充上述url，填充后上述参数默认无效
# 注，填充的时候需要填充到p，例如：http://www.dianping.com/dalian/ch10/g110p2 填充http://www.dianping.com/dalian/ch10/g110p
search_url = http://www.dianping.com/chengdu/ch10/g110p
# 是否只需要搜索页的首条内容
need_first = False
# 需要搜索的页数
need_pages = 5
[proxy]
use_proxy = True
# ip 重复次数，由于非隧道模式时，一个ip常常有1分钟左右的有效时间，单次使用有点浪费，重复使用次数
repeat_nub = 100
# 代理模式为http提取
http_extract = False
# 代理模式为秘钥访问
key_extract = True
# http链接（秘钥模式不必填）
http_link = 
# 代理服务器
proxy_host = 114.104.134.6
# 代理服务器端口
proxy_port = 20280
# 秘钥id（http模式不必填）
key_id = oz4gyvs0uqtuxv0qnbhy
# 秘钥key（http模式不必填）
key_key = yzzrhykrvon2z7cgolz4o3f6j8wqqdk3
